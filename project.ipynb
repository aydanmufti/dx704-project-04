{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md413FzAvFD8"
      },
      "source": [
        "# DX 704 Week 4 Project\n",
        "\n",
        "This week's project will test the learning speed of linear contextual bandits compared to unoptimized approaches.\n",
        "You will start with building a preference data set for evaluation, and then implement different variations of LinUCB and visualize how fast they learn the preferences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3gs-tquuzJe"
      },
      "source": [
        "The full project description, a template notebook and supporting code are available on GitHub: [Project 4 Materials](https://github.com/bu-cds-dx704/dx704-project-04).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OguIjc5idW3Z"
      },
      "source": [
        "## Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8oSLkMqvMFF"
      },
      "source": [
        "## Part 1: Collect Rating Data\n",
        "\n",
        "The file \"recipes.tsv\" in this repository has information about 100 recipes.\n",
        "Make a new file \"ratings.tsv\" with two columns, recipe_slug (from recipes.tsv) and rating.\n",
        "Populate the rating column with values between 0 and 1 where 0 is the worst and 1 is the best.\n",
        "You can assign these ratings however you want within that range, but try to make it reflect a consistent set of preferences.\n",
        "These could be your preferences, or a persona of your choosing (e.g. chocolate lover, bacon-obsessed, or sweet tooth).\n",
        "Make sure that there are at least 10 ratings of zero and at least 10 ratings of one.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAwViBgKfWER"
      },
      "source": [
        "Hint: You may find it more convenient to assign raw ratings from 1 to 5 and then remap them as follows.\n",
        "\n",
        "`ratings[\"rating\"] = (ratings[\"rating_raw\"] - 1) * 0.25`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recipe data loaded:\n",
            "Number of recipes: 100\n",
            "Number of recipe-tag pairs: 752\n",
            "\n",
            "First few recipes:\n",
            "        recipe_slug      recipe_title  \\\n",
            "0           falafel           Falafel   \n",
            "1        spamburger        Spamburger   \n",
            "2  bacon-fried-rice  Bacon Fried Rice   \n",
            "3   chicken-fingers   Chicken Fingers   \n",
            "4       apple-crisp       Apple Crisp   \n",
            "\n",
            "                                 recipe_introduction  \n",
            "0  Falafel is a popular Middle Eastern dish made ...  \n",
            "1  Spamburger is a type of hamburger that is made...  \n",
            "2  Bacon fried rice is a savory and satisfying di...  \n",
            "3  Chicken fingers are a popular dish made from c...  \n",
            "4  Apple crisp is a classic dessert made with bak...  \n",
            "\n",
            "First few recipe tags:\n",
            "   recipe_slug recipe_tag\n",
            "0  spam-musubi   hawaiian\n",
            "1  spam-musubi       nori\n",
            "2  spam-musubi    onthego\n",
            "3  spam-musubi       rice\n",
            "4  spam-musubi      snack\n",
            "\n",
            "All recipe slugs (100 total):\n",
            "['falafel', 'spamburger', 'bacon-fried-rice', 'chicken-fingers', 'apple-crisp', 'cranberry-apple-crisp', 'bacon-chocolate-chip-cookies', 'sujebi', 'pasta-primavera', 'ramen', 'brownies', 'bacon-wrapped-scallops', 'bacon-egg-muffins', 'breakfast-burritos', 'bolognese-sauce', 'croissants', 'bacon-souffle', 'souffle', 'chocolate-souffle', 'butter-croissants', 'pickled-green-beans', 'fried-oysters', 'peanut-butter-brownies', 'almond-chip-cookies', 'guacamole', 'brioche-bread', 'brioche-bread-with-chocolate', 'asparagus-quiche', 'asparagus-burger', 'ma-la-chicken', 'cold-noodles-with-tomatoes', 'tamales', 'enchiladas', 'tacos', 'burritos', 'peanut-butter-cupcakes', 'pickled-asparagus', 'chocolate-peanut-butter-cake', 'udon', 'vegetable-lasagna', 'maple-bacon-donuts', 'maple-bacon-pancakes', 'spinach-and-ricotta-stuffed-shells', 'quesadillas', 'pico-de-gallo', 'nachos', 'cold-soba-noodles-with-tomato-and-cucumber', 'fajitas', 'loaded-nachos', 'lasagna', 'chicken-nuggets', 'pain-au-chocolat', 'nacho-dip', 'nacho-salad', 'nacho-casserole', 'nacho-fries', 'tempura-udon', 'peach-crisp', 'apple-pie', 'blueberry-crisp', 'berry-crumble', 'strawberry-rhubarb-crisp', 'peach-cobbler', 'cranberry-sauce', 'cherry-cobbler', 'apple-crumble', 'chocolate-croissants', 'french-toast', 'chocolate-babka', 'cinnamon-babka', 'blueberry-crumble', 'spam-musubi', 'taco-salad', 'chiles-rellenos', 'almond-croissants', 'cranberry-relish', 'ma-la-beef', 'chocolate-cake', 'spinach-quiche', 'mushroom-quiche', 'quiche-lorraine', 'croissant-aux-amandes', 'danishes', 'spinach-and-feta-quiche', 'cold-sesame-noodles', 'soba-noodle-salad-with-peanut-dressing', 'dan-dan-noodles', 'vanilla-souffle', 'bacon-wrapped-dates', 'cherry-pie', 'berry-crisp', 'bacon-and-egg-breakfast-sandwich', 'bacon-wrapped-shrimp-skewers', 'bacon-wrapped-chicken', 'bacon-wrapped-asparagus', 'bacon-mac-and-cheese', 'chicken-alfredo-lasagna', 'classic-beef-lasagna', 'vegetarian-mushroom-lasagna', 'spinach-and-ricotta-lasagna']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the actual recipe data\n",
        "recipes = pd.read_csv('recipes.tsv', sep='\\t')\n",
        "recipe_tags = pd.read_csv('recipe-tags.tsv', sep='\\t')\n",
        "\n",
        "print(\"Recipe data loaded:\")\n",
        "print(f\"Number of recipes: {len(recipes)}\")\n",
        "print(f\"Number of recipe-tag pairs: {len(recipe_tags)}\")\n",
        "\n",
        "print(\"\\nFirst few recipes:\")\n",
        "print(recipes.head())\n",
        "\n",
        "print(\"\\nFirst few recipe tags:\")\n",
        "print(recipe_tags.head())\n",
        "\n",
        "print(f\"\\nAll recipe slugs ({len(recipes)} total):\")\n",
        "print(recipes['recipe_slug'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pork/bacon recipes (will be rated low): 20\n",
            "Sweet/baked goods (will be rated high): 33\n",
            "Savory dishes (mixed ratings): 47\n",
            "\n",
            "Rating distribution (raw 1-5 scale):\n",
            "Rating 1: 27 recipes\n",
            "Rating 2: 8 recipes\n",
            "Rating 3: 23 recipes\n",
            "Rating 4: 11 recipes\n",
            "Rating 5: 31 recipes\n",
            "\n",
            "Total recipes rated: 100\n",
            "\n",
            "Requirement check:\n",
            "Ratings that will become 0.0: 27 (need >= 10)\n",
            "Ratings that will become 1.0: 31 (need >= 10)\n",
            "Requirements met: True\n",
            "\n",
            "Examples of lowest rated recipes (pork + very savory):\n",
            "['falafel', 'spamburger', 'bacon-fried-rice', 'bacon-chocolate-chip-cookies', 'sujebi', 'ramen', 'bacon-wrapped-scallops', 'bacon-egg-muffins', 'breakfast-burritos', 'bacon-souffle']\n",
            "\n",
            "Examples of highest rated recipes (sweet/baked goods):\n",
            "['apple-crisp', 'cranberry-apple-crisp', 'brownies', 'croissants', 'butter-croissants', 'peanut-butter-brownies', 'almond-chip-cookies', 'brioche-bread', 'brioche-bread-with-chocolate', 'peanut-butter-cupcakes']\n"
          ]
        }
      ],
      "source": [
        "# Create ratings based on my very own love for baked goods and the fact I don't eat pork\n",
        "# Raw ratings from 1-5, then convert to 0-1 scale\n",
        "# Need at least 10 ratings of 1 (becomes 0.0) and 10 ratings of 5 (becomes 1.0)\n",
        "\n",
        "# Create a function to get tags for a recipe\n",
        "def get_recipe_tags(slug):\n",
        "    return recipe_tags[recipe_tags['recipe_slug'] == slug]['recipe_tag'].tolist()\n",
        "\n",
        "# Check which recipes contain pork/bacon\n",
        "def contains_pork(slug):\n",
        "    tags = get_recipe_tags(slug)\n",
        "    pork_keywords = ['bacon', 'pork', 'ham', 'spam']\n",
        "    return any(keyword in slug.lower() or keyword in str(tags).lower() for keyword in pork_keywords)\n",
        "\n",
        "# Categorize recipes\n",
        "pork_recipes = []\n",
        "sweet_baked_goods = []\n",
        "savory_dishes = []\n",
        "\n",
        "for recipe in recipes['recipe_slug']:\n",
        "    tags = get_recipe_tags(recipe)\n",
        "    \n",
        "    if contains_pork(recipe):\n",
        "        pork_recipes.append(recipe)\n",
        "    elif any(tag in ['dessert', 'baking', 'cake', 'cookies', 'brownies', 'pie', 'crisp', 'crumble', 'cobbler', 'chocolate', 'sweet', 'pastry'] for tag in tags):\n",
        "        sweet_baked_goods.append(recipe)\n",
        "    else:\n",
        "        savory_dishes.append(recipe)\n",
        "\n",
        "print(f\"Pork/bacon recipes (will be rated low): {len(pork_recipes)}\")\n",
        "print(f\"Sweet/baked goods (will be rated high): {len(sweet_baked_goods)}\")\n",
        "print(f\"Savory dishes (mixed ratings): {len(savory_dishes)}\")\n",
        "\n",
        "# Define ratings for all recipes\n",
        "ratings_raw = {}\n",
        "\n",
        "# Rating 1 (becomes 0.0) - All pork dishes + some very savory/spicy dishes\n",
        "disliked_recipes = pork_recipes + [\n",
        "    'ma-la-chicken', 'ma-la-beef', 'chiles-rellenos', 'pickled-green-beans', \n",
        "    'pickled-asparagus', 'dan-dan-noodles', 'falafel', 'sujebi'\n",
        "]\n",
        "\n",
        "# Rating 2 (becomes 0.25) - Very savory dishes, not appealing to sweet tooth\n",
        "neutral_low = [\n",
        "    'spamburger', 'fried-oysters', 'guacamole', 'pico-de-gallo',\n",
        "    'cold-noodles-with-tomatoes', 'cold-soba-noodles-with-tomato-and-cucumber',\n",
        "    'cold-sesame-noodles', 'asparagus-burger', 'asparagus-quiche'\n",
        "]\n",
        "\n",
        "# Rating 3 (becomes 0.5) - Okay savory dishes\n",
        "neutral_mid = [\n",
        "    'chicken-fingers', 'chicken-nuggets', 'ramen', 'udon', 'tempura-udon',\n",
        "    'tamales', 'enchiladas', 'tacos', 'quesadillas', 'burritos', 'fajitas',\n",
        "    'nachos', 'loaded-nachos', 'nacho-dip', 'nacho-salad', 'nacho-casserole', 'nacho-fries',\n",
        "    'taco-salad', 'pasta-primavera', 'vegetable-lasagna', 'spinach-quiche',\n",
        "    'mushroom-quiche', 'spinach-and-feta-quiche', 'soba-noodle-salad-with-peanut-dressing'\n",
        "]\n",
        "\n",
        "# Rating 4 (becomes 0.75) - Good savory dishes + some breakfast items\n",
        "liked_recipes = [\n",
        "    'breakfast-burritos', 'bolognese-sauce', 'lasagna', 'chicken-alfredo-lasagna',\n",
        "    'classic-beef-lasagna', 'vegetarian-mushroom-lasagna', 'spinach-and-ricotta-lasagna',\n",
        "    'spinach-and-ricotta-stuffed-shells', 'french-toast', 'quiche-lorraine',\n",
        "    'spam-musubi', 'souffle', 'vanilla-souffle', 'chocolate-souffle'\n",
        "]\n",
        "\n",
        "# Rating 5 (becomes 1.0) - All sweet/baked goods + some special breakfast pastries\n",
        "loved_recipes = sweet_baked_goods + [\n",
        "    'brioche-bread', 'brioche-bread-with-chocolate', 'croissants', 'butter-croissants',\n",
        "    'chocolate-croissants', 'almond-croissants', 'croissant-aux-amandes', 'danishes'\n",
        "]\n",
        "\n",
        "# Assign ratings\n",
        "for recipe in recipes['recipe_slug']:\n",
        "    if recipe in disliked_recipes:\n",
        "        ratings_raw[recipe] = 1\n",
        "    elif recipe in neutral_low:\n",
        "        ratings_raw[recipe] = 2  \n",
        "    elif recipe in neutral_mid:\n",
        "        ratings_raw[recipe] = 3\n",
        "    elif recipe in liked_recipes:\n",
        "        ratings_raw[recipe] = 4\n",
        "    elif recipe in loved_recipes:\n",
        "        ratings_raw[recipe] = 5\n",
        "    else:\n",
        "        # Default assignment for any missed recipes\n",
        "        tags = get_recipe_tags(recipe)\n",
        "        if contains_pork(recipe):\n",
        "            ratings_raw[recipe] = 1\n",
        "        elif any(tag in ['dessert', 'chocolate', 'sweet'] for tag in tags):\n",
        "            ratings_raw[recipe] = 5\n",
        "        else:\n",
        "            ratings_raw[recipe] = 3\n",
        "\n",
        "print(f\"\\nRating distribution (raw 1-5 scale):\")\n",
        "rating_counts = {}\n",
        "for rating in [1, 2, 3, 4, 5]:\n",
        "    count = sum(1 for r in ratings_raw.values() if r == rating)\n",
        "    rating_counts[rating] = count\n",
        "    print(f\"Rating {rating}: {count} recipes\")\n",
        "\n",
        "print(f\"\\nTotal recipes rated: {len(ratings_raw)}\")\n",
        "\n",
        "# Check if we meet requirements\n",
        "ratings_of_zero = rating_counts[1]  # Will become 0.0\n",
        "ratings_of_one = rating_counts[5]   # Will become 1.0\n",
        "\n",
        "print(f\"\\nRequirement check:\")\n",
        "print(f\"Ratings that will become 0.0: {ratings_of_zero} (need >= 10)\")\n",
        "print(f\"Ratings that will become 1.0: {ratings_of_one} (need >= 10)\")\n",
        "print(f\"Requirements met: {ratings_of_zero >= 10 and ratings_of_one >= 10}\")\n",
        "\n",
        "# Show some examples of each category\n",
        "print(f\"\\nExamples of lowest rated recipes (pork + very savory):\")\n",
        "lowest_rated = [recipe for recipe, rating in ratings_raw.items() if rating == 1][:10]\n",
        "print(lowest_rated)\n",
        "\n",
        "print(f\"\\nExamples of highest rated recipes (sweet/baked goods):\")\n",
        "highest_rated = [recipe for recipe, rating in ratings_raw.items() if rating == 5][:10]\n",
        "print(highest_rated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final ratings summary:\n",
            "Total recipes: 100\n",
            "Ratings of 0.0 (was rating 1): 27\n",
            "Ratings of 0.25 (was rating 2): 8\n",
            "Ratings of 0.5 (was rating 3): 23\n",
            "Ratings of 0.75 (was rating 4): 11\n",
            "Ratings of 1.0 (was rating 5): 31\n",
            "\n",
            "First few ratings:\n",
            "                         recipe_slug  rating\n",
            "23               almond-chip-cookies    1.00\n",
            "74                 almond-croissants    1.00\n",
            "4                        apple-crisp    1.00\n",
            "65                     apple-crumble    1.00\n",
            "58                         apple-pie    1.00\n",
            "28                  asparagus-burger    0.25\n",
            "27                  asparagus-quiche    0.25\n",
            "91  bacon-and-egg-breakfast-sandwich    0.00\n",
            "6       bacon-chocolate-chip-cookies    0.00\n",
            "12                 bacon-egg-muffins    0.00\n",
            "\n",
            "Last few ratings:\n",
            "                    recipe_slug  rating\n",
            "61     strawberry-rhubarb-crisp    1.00\n",
            "7                        sujebi    0.00\n",
            "72                   taco-salad    0.50\n",
            "33                        tacos    0.50\n",
            "31                      tamales    0.50\n",
            "56                 tempura-udon    0.50\n",
            "38                         udon    0.50\n",
            "87              vanilla-souffle    0.75\n",
            "39            vegetable-lasagna    0.50\n",
            "98  vegetarian-mushroom-lasagna    0.75\n",
            "\n",
            "Ratings saved to 'ratings.tsv'\n",
            "File preview:\n",
            "recipe_slug\trating\n",
            "almond-chip-cookies\t1.0\n",
            "almond-croissants\t1.0\n",
            "apple-crisp\t1.0\n",
            "apple-crumble\t1.0\n",
            "apple-pie\t1.0\n",
            "asparagus-burger\t0.25\n",
            "asparagus-quiche\t0.25\n",
            "bacon-and-egg-breakfast-sandwich\t0.0\n",
            "bacon-chocolate-chip-cookies\t0.0\n",
            "bacon-egg-muffins\t0.0\n",
            "bacon-fried-rice\t0.0\n",
            "bacon-mac-and-cheese\t0.0\n",
            "bacon-souffle\t0.0\n",
            "bacon-wrapped-asparagus\t0.0\n",
            "bacon-wrapped-chicken\t0.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the ratings DataFrame and convert to 0-1 scale\n",
        "ratings_df = pd.DataFrame({\n",
        "    'recipe_slug': list(ratings_raw.keys()),\n",
        "    'rating_raw': list(ratings_raw.values())\n",
        "})\n",
        "\n",
        "# Convert to 0-1 scale as suggested in assignment\n",
        "ratings_df['rating'] = (ratings_df['rating_raw'] - 1) * 0.25\n",
        "\n",
        "# Sort by recipe slug for consistency\n",
        "ratings_df = ratings_df.sort_values('recipe_slug')\n",
        "\n",
        "print(\"Final ratings summary:\")\n",
        "print(f\"Total recipes: {len(ratings_df)}\")\n",
        "print(f\"Ratings of 0.0 (was rating 1): {sum(ratings_df['rating'] == 0.0)}\")\n",
        "print(f\"Ratings of 0.25 (was rating 2): {sum(ratings_df['rating'] == 0.25)}\")\n",
        "print(f\"Ratings of 0.5 (was rating 3): {sum(ratings_df['rating'] == 0.5)}\")\n",
        "print(f\"Ratings of 0.75 (was rating 4): {sum(ratings_df['rating'] == 0.75)}\")\n",
        "print(f\"Ratings of 1.0 (was rating 5): {sum(ratings_df['rating'] == 1.0)}\")\n",
        "\n",
        "print(\"\\nFirst few ratings:\")\n",
        "print(ratings_df[['recipe_slug', 'rating']].head(10))\n",
        "\n",
        "print(\"\\nLast few ratings:\")\n",
        "print(ratings_df[['recipe_slug', 'rating']].tail(10))\n",
        "\n",
        "# Save to TSV file\n",
        "ratings_final = ratings_df[['recipe_slug', 'rating']]\n",
        "ratings_final.to_csv('ratings.tsv', sep='\\t', index=False)\n",
        "\n",
        "print(\"\\nRatings saved to 'ratings.tsv'\")\n",
        "print(\"File preview:\")\n",
        "print(ratings_final.head(15).to_csv(sep='\\t', index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh7UaX6OvuWo"
      },
      "source": [
        "Submit \"ratings.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiCwaZwr5M67"
      },
      "source": [
        "## Part 2: Construct Model Input\n",
        "\n",
        "Use your file \"ratings.tsv\" combined with \"recipe-tags.tsv\" to create a new file \"features.tsv\" with a column recipe_slug, a column bias which is hard-coded to one, and a column for each tag that appears in \"recipe-tags.tsv\".\n",
        "The tag column in this file should be a 0-1 encoding of the recipe tags for each recipe.\n",
        "[Pandas reshaping function methods](https://pandas.pydata.org/docs/user_guide/reshaping.html) may be helpful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WWi_JJXocEb"
      },
      "source": [
        "The bias column will make later LinUCB calculations easier since it will just be another dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHR-BsD9539j"
      },
      "source": [
        "Hint: For later modeling steps, it will be important to have the feature data (inputs) and the rating data (target outputs) in the same order.\n",
        "It is highly recommended to make sure that \"features.tsv\" and \"ratings.tsv\" have the recipe slugs in the same order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cGvj258d8nnv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ratings loaded: 100 recipes\n",
            "Recipe tags loaded: 752 tag entries\n",
            "Number of unique tags: 296\n",
            "First 10 tags: ['alfredo', 'almond', 'american', 'appetizer', 'appetizers', 'apple', 'asiancuisine', 'asparagus', 'avocado', 'bacon']\n",
            "\n",
            "Tag matrix shape: (100, 296)\n",
            "Recipes in tag matrix: 100\n",
            "\n",
            "Tag features shape after reset: (100, 297)\n",
            "Columns: ['recipe_slug', 'alfredo', 'almond', 'american', 'appetizer', 'appetizers', 'apple', 'asiancuisine', 'asparagus', 'avocado']...\n",
            "\n",
            "After adding bias column: (100, 298)\n",
            "First few columns: ['recipe_slug', 'bias', 'alfredo', 'almond', 'american']\n",
            "\n",
            "Recipes in ratings: 100\n",
            "Recipes in tag_features: 100\n",
            "Missing recipes in tag_features: 0\n",
            "Extra recipes in tag_features: 0\n",
            "\n",
            "Final features shape: (100, 298)\n",
            "Features columns: bias + 296 tags = 297 total\n",
            "\n",
            "First 5 recipes and first 10 features:\n",
            "           recipe_slug  bias  alfredo  almond  american  appetizer  \\\n",
            "0  almond-chip-cookies     1        0       1         0          0   \n",
            "1    almond-croissants     1        0       1         0          0   \n",
            "2          apple-crisp     1        0       0         0          0   \n",
            "3        apple-crumble     1        0       0         0          0   \n",
            "4            apple-pie     1        0       0         0          0   \n",
            "\n",
            "   appetizers  apple  asiancuisine  asparagus  avocado  \n",
            "0           0      0             0          0        0  \n",
            "1           0      0             0          0        0  \n",
            "2           0      1             0          0        0  \n",
            "3           0      1             0          0        0  \n",
            "4           0      1             0          0        0  \n",
            "\n",
            "Last 5 recipes:\n",
            "                    recipe_slug\n",
            "95                 tempura-udon\n",
            "96                         udon\n",
            "97              vanilla-souffle\n",
            "98            vegetable-lasagna\n",
            "99  vegetarian-mushroom-lasagna\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Load the ratings to ensure same order\n",
        "ratings = pd.read_csv('ratings.tsv', sep='\\t')\n",
        "recipe_tags = pd.read_csv('recipe-tags.tsv', sep='\\t')\n",
        "\n",
        "print(f\"Ratings loaded: {len(ratings)} recipes\")\n",
        "print(f\"Recipe tags loaded: {len(recipe_tags)} tag entries\")\n",
        "\n",
        "# Get all unique tags\n",
        "all_tags = sorted(recipe_tags['recipe_tag'].unique())\n",
        "print(f\"Number of unique tags: {len(all_tags)}\")\n",
        "print(f\"First 10 tags: {all_tags[:10]}\")\n",
        "\n",
        "# Create one-hot encoding for tags using pandas pivot\n",
        "# - creating a matrix where each row is a recipe and each column is a tag (0/1)\n",
        "tag_matrix = recipe_tags.pivot_table(\n",
        "    index='recipe_slug', \n",
        "    columns='recipe_tag', \n",
        "    aggfunc=len,  # Count occurrences (should be 1 for each recipe-tag pair)\n",
        "    fill_value=0  # Fill missing combinations with 0\n",
        ")\n",
        "\n",
        "# Convert to binary (in case there are any values > 1)\n",
        "tag_matrix = (tag_matrix > 0).astype(int)\n",
        "\n",
        "print(f\"\\nTag matrix shape: {tag_matrix.shape}\")\n",
        "print(f\"Recipes in tag matrix: {len(tag_matrix)}\")\n",
        "\n",
        "# Reset index to make recipe_slug a column\n",
        "tag_features = tag_matrix.reset_index()\n",
        "\n",
        "print(f\"\\nTag features shape after reset: {tag_features.shape}\")\n",
        "print(f\"Columns: {list(tag_features.columns)[:10]}...\")\n",
        "\n",
        "# Add bias column (hardcoded to 1 as specified)\n",
        "tag_features.insert(1, 'bias', 1)\n",
        "\n",
        "print(f\"\\nAfter adding bias column: {tag_features.shape}\")\n",
        "print(f\"First few columns: {list(tag_features.columns)[:5]}\")\n",
        "\n",
        "# Ensure we have all recipes from ratings and in the same order\n",
        "print(f\"\\nRecipes in ratings: {len(ratings)}\")\n",
        "print(f\"Recipes in tag_features: {len(tag_features)}\")\n",
        "\n",
        "# Check if all recipes from ratings are in tag_features\n",
        "missing_recipes = set(ratings['recipe_slug']) - set(tag_features['recipe_slug'])\n",
        "extra_recipes = set(tag_features['recipe_slug']) - set(ratings['recipe_slug'])\n",
        "\n",
        "print(f\"Missing recipes in tag_features: {len(missing_recipes)}\")\n",
        "if missing_recipes:\n",
        "    print(f\"Missing: {missing_recipes}\")\n",
        "\n",
        "print(f\"Extra recipes in tag_features: {len(extra_recipes)}\")\n",
        "if extra_recipes:\n",
        "    print(f\"Extra: {extra_recipes}\")\n",
        "\n",
        "# Merge with ratings to ensure same order and completeness\n",
        "features = ratings[['recipe_slug']].merge(tag_features, on='recipe_slug', how='left')\n",
        "\n",
        "# Fill any missing tag values with 0 (for recipes that don't appear in recipe-tags.tsv)\n",
        "features = features.fillna(0)\n",
        "\n",
        "print(f\"\\nFinal features shape: {features.shape}\")\n",
        "print(f\"Features columns: bias + {len(all_tags)} tags = {1 + len(all_tags)} total\")\n",
        "\n",
        "# Display first few rows and columns\n",
        "print(f\"\\nFirst 5 recipes and first 10 features:\")\n",
        "print(features.iloc[:5, :11])\n",
        "\n",
        "print(f\"\\nLast 5 recipes:\")\n",
        "print(features[['recipe_slug']].tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features saved to 'features.tsv'\n",
            "\n",
            "Verification:\n",
            "Ratings shape: (100, 2)\n",
            "Features shape: (100, 298)\n",
            "Recipe order matches: True\n",
            "Files are properly aligned and everything works\n",
            "\n",
            "Feature matrix summary:\n",
            "- Total recipes: 100\n",
            "- Total features: 297 (excluding recipe_slug)\n",
            "- Bias column: always 1\n",
            "- Tag features: 296 binary features\n",
            "\n",
            "Example feature vectors (showing first 10 features):\n",
            "           recipe_slug  bias  alfredo  almond  american  appetizer  \\\n",
            "0  almond-chip-cookies     1        0       1         0          0   \n",
            "1    almond-croissants     1        0       1         0          0   \n",
            "2          apple-crisp     1        0       0         0          0   \n",
            "3        apple-crumble     1        0       0         0          0   \n",
            "4            apple-pie     1        0       0         0          0   \n",
            "\n",
            "   appetizers  apple  asiancuisine  asparagus  avocado  \n",
            "0           0      0             0          0        0  \n",
            "1           0      0             0          0        0  \n",
            "2           0      1             0          0        0  \n",
            "3           0      1             0          0        0  \n",
            "4           0      1             0          0        0  \n",
            "\n",
            "Feature matrix sparsity:\n",
            "- Total elements: 29600\n",
            "- Non-zero elements: 752\n",
            "- Sparsity: 0.975 (97.5% zeros)\n",
            "\n",
            "Tag usage statistics:\n",
            "- Most common tags (top 10):\n",
            "  dessert: 28 recipes\n",
            "  breakfast: 20 recipes\n",
            "  cheese: 18 recipes\n",
            "  vegetarian: 17 recipes\n",
            "  comfortfood: 16 recipes\n",
            "  bacon: 15 recipes\n",
            "  baking: 15 recipes\n",
            "  brunch: 14 recipes\n",
            "  easy: 14 recipes\n",
            "  chicken: 11 recipes\n",
            "- Least common tags (bottom 10):\n",
            "  tortillabowl: 1 recipes\n",
            "  tortillachips: 1 recipes\n",
            "  traditional: 1 recipes\n",
            "  twisted: 1 recipes\n",
            "  udonnoodles: 1 recipes\n",
            "  vanilla: 1 recipes\n",
            "  vanillaicecream: 1 recipes\n",
            "  warm: 1 recipes\n",
            "  whippedcream: 1 recipes\n",
            "  yeastdough: 1 recipes\n"
          ]
        }
      ],
      "source": [
        "# Save features to TSV file\n",
        "features.to_csv('features.tsv', sep='\\t', index=False)\n",
        "print(\"Features saved to 'features.tsv'\")\n",
        "\n",
        "# Verify alignment between ratings and features\n",
        "ratings_check = pd.read_csv('ratings.tsv', sep='\\t')\n",
        "features_check = pd.read_csv('features.tsv', sep='\\t')\n",
        "\n",
        "print(f\"\\nVerification:\")\n",
        "print(f\"Ratings shape: {ratings_check.shape}\")\n",
        "print(f\"Features shape: {features_check.shape}\")\n",
        "\n",
        "# Check if recipe order is identical\n",
        "recipe_order_match = (ratings_check['recipe_slug'] == features_check['recipe_slug']).all()\n",
        "print(f\"Recipe order matches: {recipe_order_match}\")\n",
        "\n",
        "if recipe_order_match:\n",
        "    print(\"Files are properly aligned and everything works\")\n",
        "else:\n",
        "    print(\"Files are NOT aligned - this needs to be fixed - FAIL\")\n",
        "\n",
        "# Show summary statistics\n",
        "print(f\"\\nFeature matrix summary:\")\n",
        "print(f\"- Total recipes: {len(features)}\")\n",
        "print(f\"- Total features: {features.shape[1] - 1} (excluding recipe_slug)\")  \n",
        "print(f\"- Bias column: always 1\")\n",
        "print(f\"- Tag features: {features.shape[1] - 2} binary features\")\n",
        "\n",
        "# Show some examples of feature vectors\n",
        "print(f\"\\nExample feature vectors (showing first 10 features):\")\n",
        "# First 5 recipes, first 11 columns\n",
        "example_features = features.iloc[:5, :11]  \n",
        "print(example_features)\n",
        "\n",
        "# Check sparsity of the feature matrix\n",
        "# Exclude recipe_slug and bias\n",
        "feature_matrix = features.iloc[:, 2:].values  \n",
        "total_elements = feature_matrix.size\n",
        "nonzero_elements = np.count_nonzero(feature_matrix)\n",
        "sparsity = 1 - (nonzero_elements / total_elements)\n",
        "\n",
        "print(f\"\\nFeature matrix sparsity:\")\n",
        "print(f\"- Total elements: {total_elements}\")\n",
        "print(f\"- Non-zero elements: {nonzero_elements}\")\n",
        "print(f\"- Sparsity: {sparsity:.3f} ({sparsity*100:.1f}% zeros)\")\n",
        "\n",
        "# Show tag distribution\n",
        "# Count how many recipes have each tag\n",
        "tag_counts = feature_matrix.sum(axis=0) \n",
        "print(f\"\\nTag usage statistics:\")\n",
        "print(f\"- Most common tags (top 10):\")\n",
        "tag_names = features.columns[2:].tolist()\n",
        "tag_freq = list(zip(tag_names, tag_counts))\n",
        "tag_freq_sorted = sorted(tag_freq, key=lambda x: x[1], reverse=True)\n",
        "for tag, count in tag_freq_sorted[:10]:\n",
        "    print(f\"  {tag}: {count} recipes\")\n",
        "\n",
        "print(f\"- Least common tags (bottom 10):\")\n",
        "for tag, count in tag_freq_sorted[-10:]:\n",
        "    print(f\"  {tag}: {count} recipes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w63ji-Oi6oH7"
      },
      "source": [
        "Submit \"features.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TeXvznlwJzo"
      },
      "source": [
        "## Part 3: Linear Preference Model\n",
        "\n",
        "Use your feature and rating files to build a ridge regression model with ridge regression's regularization parameter $\\alpha$ set to 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVlUnVv4oDIk"
      },
      "source": [
        "Hint: If you are using scikit-learn modeling classes, you should use `fit_intercept=False` since that intercept value will be redundant with the bias coefficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLrBu-z7A45W"
      },
      "source": [
        "Hint: The estimate component of the bounds should match the previous estimate, so you should be able to just focus on the variance component of the bounds now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dxtiRunPwPYz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded and verified:\n",
            "Features shape: (100, 298)\n",
            "Ratings shape: (100, 2)\n",
            "\n",
            "Feature matrix X shape: (100, 297)\n",
            "Target vector y shape: (100,)\n",
            "y range: 0.0 to 1.0\n",
            "\n",
            "Ridge regression model trained:\n",
            "Number of coefficients: 297\n",
            "Expected number: 297 (bias + 296 tags)\n",
            "\n",
            "Model Performance:\n",
            "Mean Squared Error: 0.0019\n",
            "R² Score: 0.9876\n",
            "\n",
            "Coefficient Statistics:\n",
            "Min coefficient: -0.3440\n",
            "Max coefficient: 0.3526\n",
            "Mean absolute coefficient: 0.0403\n",
            "Bias coefficient: 0.3526\n",
            "\n",
            "Example Predictions (first 10 recipes):\n",
            "almond-chip-cookies       | Actual: 1.00 | Predicted: 0.94 | Error: 0.063\n",
            "almond-croissants         | Actual: 1.00 | Predicted: 1.03 | Error: -0.025\n",
            "apple-crisp               | Actual: 1.00 | Predicted: 0.99 | Error: 0.005\n",
            "apple-crumble             | Actual: 1.00 | Predicted: 1.02 | Error: -0.018\n",
            "apple-pie                 | Actual: 1.00 | Predicted: 1.00 | Error: -0.001\n",
            "asparagus-burger          | Actual: 0.25 | Predicted: 0.25 | Error: 0.001\n",
            "asparagus-quiche          | Actual: 0.25 | Predicted: 0.27 | Error: -0.015\n",
            "bacon-and-egg-breakfast-sandwich | Actual: 0.00 | Predicted: 0.00 | Error: -0.001\n",
            "bacon-chocolate-chip-cookies | Actual: 0.00 | Predicted: 0.10 | Error: -0.104\n",
            "bacon-egg-muffins         | Actual: 0.00 | Predicted: 0.03 | Error: -0.026\n",
            "\n",
            "Top 10 most positive tag coefficients (preference indicators):\n",
            "  baking              : +0.2521\n",
            "  dessert             : +0.2051\n",
            "  french              : +0.1595\n",
            "  frenchpastry        : +0.1580\n",
            "  peach               : +0.1286\n",
            "  italian             : +0.1256\n",
            "  sweet               : +0.1210\n",
            "  almond              : +0.1051\n",
            "  sweettreat          : +0.1031\n",
            "  cranberry           : +0.1016\n",
            "\n",
            "Top 10 most negative tag coefficients (dislike indicators):\n",
            "  spicyfood           : -0.0874\n",
            "  stuffedpeppers      : -0.0874\n",
            "  handtorndough       : -0.0962\n",
            "  koreancuisine       : -0.0962\n",
            "  sweetandsalty       : -0.1038\n",
            "  pickledvegetables   : -0.1061\n",
            "  creamcheese         : -0.1527\n",
            "  danish              : -0.1527\n",
            "  hamandcheese        : -0.1527\n",
            "  bacon               : -0.3440\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the aligned data\n",
        "features = pd.read_csv('features.tsv', sep='\\t')\n",
        "ratings = pd.read_csv('ratings.tsv', sep='\\t')\n",
        "\n",
        "# Verify alignment\n",
        "assert (features['recipe_slug'] == ratings['recipe_slug']).all(), \"Data not aligned!\"\n",
        "\n",
        "print(\"Data loaded and verified:\")\n",
        "print(f\"Features shape: {features.shape}\")\n",
        "print(f\"Ratings shape: {ratings.shape}\")\n",
        "\n",
        "# Prepare feature matrix (exclude recipe_slug column)\n",
        "X = features.drop('recipe_slug', axis=1).values\n",
        "y = ratings['rating'].values\n",
        "\n",
        "print(f\"\\nFeature matrix X shape: {X.shape}\")\n",
        "print(f\"Target vector y shape: {y.shape}\")\n",
        "print(f\"y range: {y.min()} to {y.max()}\")\n",
        "\n",
        "# Build ridge regression model with alpha=1 and fit_intercept=False\n",
        "# fit_intercept=False because we already have a bias column\n",
        "ridge_model = Ridge(alpha=1.0, fit_intercept=False, random_state=42)\n",
        "ridge_model.fit(X, y)\n",
        "\n",
        "print(f\"\\nRidge regression model trained:\")\n",
        "print(f\"Number of coefficients: {len(ridge_model.coef_)}\")\n",
        "print(f\"Expected number: {X.shape[1]} (bias + {X.shape[1]-1} tags)\")\n",
        "\n",
        "# Model performance metrics\n",
        "y_pred = ridge_model.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "print(f\"\\nModel Performance:\")\n",
        "print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "print(f\"R² Score: {r2:.4f}\")\n",
        "\n",
        "# Show coefficient statistics\n",
        "coefficients = ridge_model.coef_\n",
        "print(f\"\\nCoefficient Statistics:\")\n",
        "print(f\"Min coefficient: {coefficients.min():.4f}\")\n",
        "print(f\"Max coefficient: {coefficients.max():.4f}\")\n",
        "print(f\"Mean absolute coefficient: {np.abs(coefficients).mean():.4f}\")\n",
        "\n",
        "# Show bias coefficient (first coefficient)\n",
        "print(f\"Bias coefficient: {coefficients[0]:.4f}\")\n",
        "\n",
        "# Show some example predictions vs actual ratings\n",
        "print(f\"\\nExample Predictions (first 10 recipes):\")\n",
        "for i in range(10):\n",
        "    recipe = features.iloc[i]['recipe_slug']\n",
        "    actual = y[i]\n",
        "    predicted = y_pred[i]\n",
        "    print(f\"{recipe:25} | Actual: {actual:.2f} | Predicted: {predicted:.2f} | Error: {actual-predicted:.3f}\")\n",
        "\n",
        "# Show top positive and negative tag coefficients (excluding bias)\n",
        "feature_names = features.columns[1:].tolist()  # Exclude recipe_slug\n",
        "coef_with_names = list(zip(feature_names, coefficients))\n",
        "\n",
        "# Sort by coefficient value\n",
        "coef_sorted = sorted(coef_with_names[1:], key=lambda x: x[1], reverse=True)  # Exclude bias\n",
        "\n",
        "print(f\"\\nTop 10 most positive tag coefficients (preference indicators):\")\n",
        "for tag, coef in coef_sorted[:10]:\n",
        "    print(f\"  {tag:20}: {coef:+.4f}\")\n",
        "\n",
        "print(f\"\\nTop 10 most negative tag coefficients (dislike indicators):\")\n",
        "for tag, coef in coef_sorted[-10:]:\n",
        "    print(f\"  {tag:20}: {coef:+.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw9LaHF_8tsA"
      },
      "source": [
        "Save the coefficients of this model in a file \"model.tsv\" with columns \"recipe_tag\" and \"coefficient\".\n",
        "Do not add anything for the `intercept_` attribute of a scikit-learn model; this will be covered by the coefficient for the bias column added in part 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fiMBlU4L8uSR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating model coefficients file:\n",
            "Number of features: 297\n",
            "Number of coefficients: 297\n",
            "\n",
            "Model coefficients summary:\n",
            "Shape: (297, 2)\n",
            "First few entries:\n",
            "  recipe_tag  coefficient\n",
            "0       bias     0.352603\n",
            "1    alfredo     0.047706\n",
            "2     almond     0.105088\n",
            "3   american     0.032247\n",
            "4  appetizer    -0.043827\n",
            "\n",
            "Last few entries:\n",
            "       recipe_tag  coefficient\n",
            "292    vegetarian    -0.014240\n",
            "293          warm     0.035646\n",
            "294  whippedcream    -0.017843\n",
            "295        winter     0.031184\n",
            "296    yeastdough     0.022446\n",
            "\n",
            "Model coefficients saved to 'model.tsv'\n",
            "Verification - loaded model.tsv:\n",
            "Shape: (297, 2)\n",
            "Columns: ['recipe_tag', 'coefficient']\n",
            "\n",
            "Top 5 most positive coefficients (loves these):\n",
            "  bias                : +0.3526\n",
            "  baking              : +0.2521\n",
            "  dessert             : +0.2051\n",
            "  french              : +0.1595\n",
            "  frenchpastry        : +0.1580\n",
            "\n",
            "Top 5 most negative coefficients (dislikes these):\n",
            "  bacon               : -0.3440\n",
            "  creamcheese         : -0.1527\n",
            "  danish              : -0.1527\n",
            "  hamandcheese        : -0.1527\n",
            "  pickledvegetables   : -0.1061\n",
            "\n",
            "Bias coefficient: 0.3526\n",
            "This represents the baseline preference level before considering any specific tags.\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Create model coefficients DataFrame\n",
        "# feature_names includes 'bias' + all tag names (excluding recipe_slug)\n",
        "feature_names = features.columns[1:].tolist()  # Skip recipe_slug column\n",
        "coefficients = ridge_model.coef_\n",
        "\n",
        "print(f\"Creating model coefficients file:\")\n",
        "print(f\"Number of features: {len(feature_names)}\")\n",
        "print(f\"Number of coefficients: {len(coefficients)}\")\n",
        "\n",
        "# Create DataFrame with recipe_tag and coefficient columns\n",
        "model_df = pd.DataFrame({\n",
        "    'recipe_tag': feature_names,\n",
        "    'coefficient': coefficients\n",
        "})\n",
        "\n",
        "print(f\"\\nModel coefficients summary:\")\n",
        "print(f\"Shape: {model_df.shape}\")\n",
        "print(f\"First few entries:\")\n",
        "print(model_df.head())\n",
        "\n",
        "print(f\"\\nLast few entries:\")\n",
        "print(model_df.tail())\n",
        "\n",
        "# Save to TSV file\n",
        "model_df.to_csv('model.tsv', sep='\\t', index=False)\n",
        "print(f\"\\nModel coefficients saved to 'model.tsv'\")\n",
        "\n",
        "# Verification - load and check\n",
        "model_check = pd.read_csv('model.tsv', sep='\\t')\n",
        "print(f\"Verification - loaded model.tsv:\")\n",
        "print(f\"Shape: {model_check.shape}\")\n",
        "print(f\"Columns: {model_check.columns.tolist()}\")\n",
        "\n",
        "# Show most important coefficients again for verification\n",
        "print(f\"\\nTop 5 most positive coefficients (loves these):\")\n",
        "top_positive = model_df.nlargest(5, 'coefficient')\n",
        "for _, row in top_positive.iterrows():\n",
        "    print(f\"  {row['recipe_tag']:20}: {row['coefficient']:+.4f}\")\n",
        "\n",
        "print(f\"\\nTop 5 most negative coefficients (dislikes these):\")\n",
        "top_negative = model_df.nsmallest(5, 'coefficient')\n",
        "for _, row in top_negative.iterrows():\n",
        "    print(f\"  {row['recipe_tag']:20}: {row['coefficient']:+.4f}\")\n",
        "\n",
        "# Check that bias is included\n",
        "bias_coef = model_df[model_df['recipe_tag'] == 'bias']['coefficient'].iloc[0]\n",
        "print(f\"\\nBias coefficient: {bias_coef:.4f}\")\n",
        "print(f\"This represents the baseline preference level before considering any specific tags.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86uS_zZ0wQxC"
      },
      "source": [
        "Submit \"model.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1Nfs7zCsDpj"
      },
      "source": [
        "## Part 4: Recipe Estimates\n",
        "\n",
        "Use the recipe model to estimate the score of every recipe.\n",
        "Save these estimates to a file \"estimates.tsv\" with columns recipe_slug and score_estimate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pIClPwYVso5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated score estimates:\n",
            "Number of recipes: 100\n",
            "Estimate range: -0.0178 to 1.0498\n",
            "\n",
            "Estimates DataFrame shape: (100, 2)\n",
            "First few estimates:\n",
            "                        recipe_slug  score_estimate\n",
            "0               almond-chip-cookies        0.936994\n",
            "1                 almond-croissants        1.025366\n",
            "2                       apple-crisp        0.994851\n",
            "3                     apple-crumble        1.017843\n",
            "4                         apple-pie        1.001116\n",
            "5                  asparagus-burger        0.248667\n",
            "6                  asparagus-quiche        0.265099\n",
            "7  bacon-and-egg-breakfast-sandwich        0.001166\n",
            "8      bacon-chocolate-chip-cookies        0.103821\n",
            "9                 bacon-egg-muffins        0.025735\n",
            "\n",
            "Comparison with actual ratings:\n",
            "Mean Absolute Error: 0.0339\n",
            "Max Absolute Error: 0.1527\n",
            "\n",
            "Top 10 highest estimated scores (model recommendations):\n",
            "blueberry-crisp           | Estimate: 1.050 | Actual: 1.000\n",
            "brioche-bread-with-chocolate | Estimate: 1.048 | Actual: 1.000\n",
            "almond-croissants         | Estimate: 1.025 | Actual: 1.000\n",
            "berry-crumble             | Estimate: 1.024 | Actual: 1.000\n",
            "apple-crumble             | Estimate: 1.018 | Actual: 1.000\n",
            "peanut-butter-cupcakes    | Estimate: 1.007 | Actual: 1.000\n",
            "apple-pie                 | Estimate: 1.001 | Actual: 1.000\n",
            "cherry-cobbler            | Estimate: 0.997 | Actual: 1.000\n",
            "apple-crisp               | Estimate: 0.995 | Actual: 1.000\n",
            "strawberry-rhubarb-crisp  | Estimate: 0.992 | Actual: 1.000\n",
            "\n",
            "Top 10 lowest estimated scores:\n",
            "bacon-fried-rice          | Estimate: -0.018 | Actual: 0.000\n",
            "bacon-wrapped-shrimp-skewers | Estimate: -0.017 | Actual: 0.000\n",
            "bacon-wrapped-scallops    | Estimate: -0.008 | Actual: 0.000\n",
            "breakfast-burritos        | Estimate: -0.007 | Actual: 0.000\n",
            "bacon-and-egg-breakfast-sandwich | Estimate: 0.001 | Actual: 0.000\n",
            "ma-la-chicken             | Estimate: 0.007 | Actual: 0.000\n",
            "maple-bacon-pancakes      | Estimate: 0.011 | Actual: 0.000\n",
            "dan-dan-noodles           | Estimate: 0.017 | Actual: 0.000\n",
            "bacon-wrapped-chicken     | Estimate: 0.019 | Actual: 0.000\n",
            "bacon-wrapped-asparagus   | Estimate: 0.022 | Actual: 0.000\n",
            "\n",
            "Score estimates saved to 'estimates.tsv'\n",
            "Verification - loaded estimates.tsv:\n",
            "Shape: (100, 2)\n",
            "Columns: ['recipe_slug', 'score_estimate']\n",
            "Sample entries:\n",
            "           recipe_slug  score_estimate\n",
            "0  almond-chip-cookies        0.936994\n",
            "1    almond-croissants        1.025366\n",
            "2          apple-crisp        0.994851\n",
            "3        apple-crumble        1.017843\n",
            "4            apple-pie        1.001116\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Load the feature data and use our trained model to generate estimates\n",
        "features = pd.read_csv('features.tsv', sep='\\t')\n",
        "ratings = pd.read_csv('ratings.tsv', sep='\\t')\n",
        "\n",
        "# Prepare feature matrix (exclude recipe_slug column)\n",
        "X = features.drop('recipe_slug', axis=1).values\n",
        "\n",
        "# Generate score estimates using the trained ridge regression model\n",
        "score_estimates = ridge_model.predict(X)\n",
        "\n",
        "print(f\"Generated score estimates:\")\n",
        "print(f\"Number of recipes: {len(score_estimates)}\")\n",
        "print(f\"Estimate range: {score_estimates.min():.4f} to {score_estimates.max():.4f}\")\n",
        "\n",
        "# Create estimates DataFrame\n",
        "estimates_df = pd.DataFrame({\n",
        "    'recipe_slug': features['recipe_slug'],\n",
        "    'score_estimate': score_estimates\n",
        "})\n",
        "\n",
        "print(f\"\\nEstimates DataFrame shape: {estimates_df.shape}\")\n",
        "print(f\"First few estimates:\")\n",
        "print(estimates_df.head(10))\n",
        "\n",
        "# Compare estimates with actual ratings for verification\n",
        "comparison = estimates_df.merge(ratings, on='recipe_slug')\n",
        "comparison['error'] = comparison['rating'] - comparison['score_estimate']\n",
        "comparison['abs_error'] = abs(comparison['error'])\n",
        "\n",
        "print(f\"\\nComparison with actual ratings:\")\n",
        "print(f\"Mean Absolute Error: {comparison['abs_error'].mean():.4f}\")\n",
        "print(f\"Max Absolute Error: {comparison['abs_error'].max():.4f}\")\n",
        "\n",
        "# Show recipes with highest estimated scores (model's top recommendations)\n",
        "print(f\"\\nTop 10 highest estimated scores (model recommendations):\")\n",
        "top_estimates = estimates_df.nlargest(10, 'score_estimate')\n",
        "for _, row in top_estimates.iterrows():\n",
        "    actual_rating = ratings[ratings['recipe_slug'] == row['recipe_slug']]['rating'].iloc[0]\n",
        "    print(f\"{row['recipe_slug']:25} | Estimate: {row['score_estimate']:.3f} | Actual: {actual_rating:.3f}\")\n",
        "\n",
        "# Show recipes with lowest estimated scores\n",
        "print(f\"\\nTop 10 lowest estimated scores:\")\n",
        "low_estimates = estimates_df.nsmallest(10, 'score_estimate')\n",
        "for _, row in low_estimates.iterrows():\n",
        "    actual_rating = ratings[ratings['recipe_slug'] == row['recipe_slug']]['rating'].iloc[0]\n",
        "    print(f\"{row['recipe_slug']:25} | Estimate: {row['score_estimate']:.3f} | Actual: {actual_rating:.3f}\")\n",
        "\n",
        "# Save estimates to TSV file\n",
        "estimates_df.to_csv('estimates.tsv', sep='\\t', index=False)\n",
        "print(f\"\\nScore estimates saved to 'estimates.tsv'\")\n",
        "\n",
        "# Verification\n",
        "estimates_check = pd.read_csv('estimates.tsv', sep='\\t')\n",
        "print(f\"Verification - loaded estimates.tsv:\")\n",
        "print(f\"Shape: {estimates_check.shape}\")\n",
        "print(f\"Columns: {estimates_check.columns.tolist()}\")\n",
        "print(f\"Sample entries:\")\n",
        "print(estimates_check.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5t3uSE_srMA"
      },
      "source": [
        "Submit \"estimates.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTBplNhRst8q"
      },
      "source": [
        "## Part 5: LinUCB Bounds\n",
        "\n",
        "Calculate the upper bounds of LinUCB using data corresponding to trying every recipe once and receiving the rating in \"ratings.tsv\" as the reward.\n",
        "Keep the ridge regression regularization parameter at 1, and set LinUCB's $\\alpha$ parameter to 2.\n",
        "Save these upper bounds to a file \"bounds.tsv\" with columns recipe_slug and score_bound."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kY7aWD_PuP0W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded:\n",
            "Feature matrix X shape: (100, 297)\n",
            "Ratings vector y shape: (100,)\n",
            "Number of recipes: 100\n",
            "\n",
            "LinUCB Parameters:\n",
            "Ridge regularization (alpha): 1.0\n",
            "LinUCB confidence (alpha): 2.0\n",
            "Matrix A shape: (297, 297)\n",
            "A condition number: 1.55e+02\n",
            "A_inv computed successfully\n",
            "Theta_hat shape: (297,)\n",
            "Theta_hat range: -0.3440 to 0.3526\n",
            "\n",
            "Coefficient verification:\n",
            "Max difference with Ridge: 0.000000\n",
            "Coefficients match: True\n",
            "\n",
            "LinUCB bounds calculated:\n",
            "Score bounds range: 1.5984 to 2.8875\n",
            "Point estimates range: -0.0178 to 1.0498\n",
            "Max difference with previous estimates: 0.000000\n",
            "\n",
            "Bounds DataFrame shape: (100, 2)\n",
            "First few bounds:\n",
            "                        recipe_slug  score_bound\n",
            "0               almond-chip-cookies     2.660453\n",
            "1                 almond-croissants     2.731221\n",
            "2                       apple-crisp     2.771193\n",
            "3                     apple-crumble     2.887515\n",
            "4                         apple-pie     2.851369\n",
            "5                  asparagus-burger     2.112670\n",
            "6                  asparagus-quiche     2.076131\n",
            "7  bacon-and-egg-breakfast-sandwich     1.778568\n",
            "8      bacon-chocolate-chip-cookies     1.791977\n",
            "9                 bacon-egg-muffins     1.804921\n",
            "\n",
            "Top 10 highest LinUCB upper bounds:\n",
            "apple-crumble             | Bound: 2.888 | Est: 1.018 | Actual: 1.000 | Width: 1.870\n",
            "pain-au-chocolat          | Bound: 2.853 | Est: 0.964 | Actual: 1.000 | Width: 1.889\n",
            "strawberry-rhubarb-crisp  | Bound: 2.852 | Est: 0.992 | Actual: 1.000 | Width: 1.860\n",
            "apple-pie                 | Bound: 2.851 | Est: 1.001 | Actual: 1.000 | Width: 1.850\n",
            "chocolate-babka           | Bound: 2.827 | Est: 0.978 | Actual: 1.000 | Width: 1.850\n",
            "brioche-bread             | Bound: 2.806 | Est: 0.969 | Actual: 1.000 | Width: 1.837\n",
            "cranberry-apple-crisp     | Bound: 2.800 | Est: 0.974 | Actual: 1.000 | Width: 1.826\n",
            "peanut-butter-cupcakes    | Bound: 2.787 | Est: 1.007 | Actual: 1.000 | Width: 1.780\n",
            "croissant-aux-amandes     | Bound: 2.776 | Est: 0.933 | Actual: 1.000 | Width: 1.844\n",
            "apple-crisp               | Bound: 2.771 | Est: 0.995 | Actual: 1.000 | Width: 1.776\n",
            "\n",
            "LinUCB bounds saved to 'bounds.tsv'\n",
            "Verification - loaded bounds.tsv:\n",
            "Shape: (100, 2)\n",
            "Columns: ['recipe_slug', 'score_bound']\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Load data\n",
        "features = pd.read_csv('features.tsv', sep='\\t')\n",
        "ratings = pd.read_csv('ratings.tsv', sep='\\t')\n",
        "estimates = pd.read_csv('estimates.tsv', sep='\\t')\n",
        "\n",
        "# Prepare data matrices\n",
        "X = features.drop('recipe_slug', axis=1).values  # Feature matrix (100 x 297)\n",
        "y = ratings['rating'].values  # Ratings vector (100,)\n",
        "recipe_slugs = features['recipe_slug'].values\n",
        "\n",
        "print(f\"Data loaded:\")\n",
        "print(f\"Feature matrix X shape: {X.shape}\")\n",
        "print(f\"Ratings vector y shape: {y.shape}\")\n",
        "print(f\"Number of recipes: {len(recipe_slugs)}\")\n",
        "\n",
        "# LinUCB parameters\n",
        "ridge_alpha = 1.0  # Regularization parameter (same as Part 3)\n",
        "linucb_alpha = 2.0  # LinUCB confidence parameter\n",
        "\n",
        "print(f\"\\nLinUCB Parameters:\")\n",
        "print(f\"Ridge regularization (alpha): {ridge_alpha}\")\n",
        "print(f\"LinUCB confidence (alpha): {linucb_alpha}\")\n",
        "\n",
        "# Simulate LinUCB scenario: we've tried every recipe once\n",
        "# This means our design matrix D is just X (all features)\n",
        "# and our reward vector c is just y (all ratings)\n",
        "\n",
        "# Calculate A = D^T D + I_d (where D is our feature matrix X)\n",
        "# A represents the precision matrix for the posterior\n",
        "d = X.shape[1]  # Number of features (297)\n",
        "I_d = np.eye(d)  # Identity matrix\n",
        "A = X.T @ X + ridge_alpha * I_d  # (297 x 297)\n",
        "\n",
        "print(f\"Matrix A shape: {A.shape}\")\n",
        "print(f\"A condition number: {np.linalg.cond(A):.2e}\")\n",
        "\n",
        "# Calculate A_inv for confidence bound computation\n",
        "A_inv = np.linalg.inv(A)\n",
        "print(f\"A_inv computed successfully\")\n",
        "\n",
        "# Calculate b = D^T c (where c is reward vector y)\n",
        "b = X.T @ y  # (297,)\n",
        "\n",
        "# Calculate theta_hat = A_inv @ b (ridge regression coefficients)\n",
        "theta_hat = A_inv @ b\n",
        "\n",
        "print(f\"Theta_hat shape: {theta_hat.shape}\")\n",
        "print(f\"Theta_hat range: {theta_hat.min():.4f} to {theta_hat.max():.4f}\")\n",
        "\n",
        "# Verify our theta_hat matches the ridge regression from Part 3\n",
        "ridge_model = Ridge(alpha=ridge_alpha, fit_intercept=False)\n",
        "ridge_model.fit(X, y)\n",
        "ridge_coef = ridge_model.coef_\n",
        "\n",
        "print(f\"\\nCoefficient verification:\")\n",
        "print(f\"Max difference with Ridge: {np.max(np.abs(theta_hat - ridge_coef)):.6f}\")\n",
        "print(f\"Coefficients match: {np.allclose(theta_hat, ridge_coef)}\")\n",
        "\n",
        "# Calculate LinUCB upper bounds for each recipe\n",
        "# Upper bound = z^T theta_hat + alpha * sqrt(z^T A_inv z)\n",
        "# where z is the feature vector for each recipe\n",
        "\n",
        "score_bounds = np.zeros(len(recipe_slugs))\n",
        "score_estimates_check = np.zeros(len(recipe_slugs))\n",
        "\n",
        "for i in range(len(recipe_slugs)):\n",
        "    z = X[i, :]  # Feature vector for recipe i\n",
        "    \n",
        "    # Point estimate: z^T theta_hat\n",
        "    point_estimate = z @ theta_hat\n",
        "    score_estimates_check[i] = point_estimate\n",
        "    \n",
        "    # Confidence width: alpha * sqrt(z^T A_inv z)\n",
        "    confidence_width = linucb_alpha * np.sqrt(z @ A_inv @ z)\n",
        "    \n",
        "    # Upper confidence bound\n",
        "    upper_bound = point_estimate + confidence_width\n",
        "    score_bounds[i] = upper_bound\n",
        "\n",
        "print(f\"\\nLinUCB bounds calculated:\")\n",
        "print(f\"Score bounds range: {score_bounds.min():.4f} to {score_bounds.max():.4f}\")\n",
        "print(f\"Point estimates range: {score_estimates_check.min():.4f} to {score_estimates_check.max():.4f}\")\n",
        "\n",
        "# Verify point estimates match our previous estimates\n",
        "estimates_diff = np.max(np.abs(score_estimates_check - estimates['score_estimate'].values))\n",
        "print(f\"Max difference with previous estimates: {estimates_diff:.6f}\")\n",
        "\n",
        "# Create bounds DataFrame\n",
        "bounds_df = pd.DataFrame({\n",
        "    'recipe_slug': recipe_slugs,\n",
        "    'score_bound': score_bounds\n",
        "})\n",
        "\n",
        "print(f\"\\nBounds DataFrame shape: {bounds_df.shape}\")\n",
        "print(f\"First few bounds:\")\n",
        "print(bounds_df.head(10))\n",
        "\n",
        "# Show recipes with highest upper bounds (LinUCB recommendations)\n",
        "print(f\"\\nTop 10 highest LinUCB upper bounds:\")\n",
        "top_bounds = bounds_df.nlargest(10, 'score_bound')\n",
        "for _, row in top_bounds.iterrows():\n",
        "    recipe = row['recipe_slug']\n",
        "    bound = row['score_bound']\n",
        "    estimate = estimates[estimates['recipe_slug'] == recipe]['score_estimate'].iloc[0]\n",
        "    actual = ratings[ratings['recipe_slug'] == recipe]['rating'].iloc[0]\n",
        "    confidence_width = bound - estimate\n",
        "    print(f\"{recipe:25} | Bound: {bound:.3f} | Est: {estimate:.3f} | Actual: {actual:.3f} | Width: {confidence_width:.3f}\")\n",
        "\n",
        "# Save bounds to TSV file\n",
        "bounds_df.to_csv('bounds.tsv', sep='\\t', index=False)\n",
        "print(f\"\\nLinUCB bounds saved to 'bounds.tsv'\")\n",
        "\n",
        "# Verification\n",
        "bounds_check = pd.read_csv('bounds.tsv', sep='\\t')\n",
        "print(f\"Verification - loaded bounds.tsv:\")\n",
        "print(f\"Shape: {bounds_check.shape}\")\n",
        "print(f\"Columns: {bounds_check.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ4RPppFvG-S"
      },
      "source": [
        "Submit \"bounds.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfazOSWlwYsP"
      },
      "source": [
        "## Part 6: Make Online Recommendations\n",
        "\n",
        "Implement LinUCB to make 100 recommendations starting with no data and using the same parameters as in part 5.\n",
        "One recommendation should be made at a time and you can break ties arbitrarily.\n",
        "After each recommendation, use the rating from part 1 as the reward to update the LinUCB data.\n",
        "Record the recommendations made in a file \"recommendations.tsv\" with columns \"recipe_slug\", \"score_bound\", and \"reward\".\n",
        "The rows in this file should be in the same order as the recommendations were made."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hQ7r45B7wm4v"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Online LinUCB Setup:\n",
            "Number of recipes: 100\n",
            "Feature dimensions: 297\n",
            "Parameters: ridge_alpha=1.0, linucb_alpha=2.0\n",
            "Round 1/100\n",
            "Round 11/100\n",
            "Round 21/100\n",
            "Round 31/100\n",
            "Round 41/100\n",
            "Round 51/100\n",
            "Round 61/100\n",
            "Round 71/100\n",
            "Round 81/100\n",
            "Round 91/100\n",
            "Completed 100 recommendations\n",
            "\n",
            "Recommendations summary:\n",
            "Shape: (100, 3)\n",
            "Average reward: 0.5275\n",
            "Total reward: 52.75\n",
            "\n",
            "First 10 recommendations:\n",
            " 1: apple-crumble             | Bound: 7.483 | Reward: 1.00\n",
            " 2: ramen                     | Bound: 7.270 | Reward: 0.00\n",
            " 3: quesadillas               | Bound: 7.236 | Reward: 0.50\n",
            " 4: ma-la-chicken             | Bound: 7.161 | Reward: 0.00\n",
            " 5: chocolate-babka           | Bound: 6.963 | Reward: 1.00\n",
            " 6: pain-au-chocolat          | Bound: 7.011 | Reward: 1.00\n",
            " 7: spamburger                | Bound: 6.988 | Reward: 0.00\n",
            " 8: bacon-fried-rice          | Bound: 6.883 | Reward: 0.00\n",
            " 9: nacho-fries               | Bound: 6.690 | Reward: 0.50\n",
            "10: cranberry-relish          | Bound: 6.692 | Reward: 1.00\n",
            "\n",
            "Last 10 recommendations:\n",
            "91: bacon-wrapped-dates       | Bound: 3.647 | Reward: 0.00\n",
            "92: blueberry-crumble         | Bound: 3.587 | Reward: 1.00\n",
            "93: cinnamon-babka            | Bound: 3.551 | Reward: 1.00\n",
            "94: vegetarian-mushroom-lasagna | Bound: 3.543 | Reward: 0.75\n",
            "95: chocolate-souffle         | Bound: 3.401 | Reward: 0.75\n",
            "96: berry-crumble             | Bound: 3.282 | Reward: 1.00\n",
            "97: spinach-and-ricotta-stuffed-shells | Bound: 3.272 | Reward: 0.75\n",
            "98: butter-croissants         | Bound: 3.117 | Reward: 1.00\n",
            "99: vegetable-lasagna         | Bound: 2.817 | Reward: 0.50\n",
            "100: bacon-souffle             | Bound: 2.550 | Reward: 0.00\n",
            "\n",
            "Performance analysis:\n",
            "Final cumulative reward: 52.75\n",
            "Final cumulative regret: 47.25\n",
            "Average reward per recommendation: 0.5275\n",
            "\n",
            "Reward distribution:\n",
            "  Reward 0.0: 27 recipes\n",
            "  Reward 0.25: 8 recipes\n",
            "  Reward 0.5: 23 recipes\n",
            "  Reward 0.75: 11 recipes\n",
            "  Reward 1.0: 31 recipes\n",
            "\n",
            "Recommendations saved to 'recommendations.tsv'\n",
            "Verification - loaded recommendations.tsv:\n",
            "Shape: (100, 3)\n",
            "Columns: ['recipe_slug', 'score_bound', 'reward']\n",
            "Sample entries:\n",
            "       recipe_slug  score_bound  reward\n",
            "0    apple-crumble     7.483315     1.0\n",
            "1            ramen     7.270093     0.0\n",
            "2      quesadillas     7.235617     0.5\n",
            "3    ma-la-chicken     7.161007     0.0\n",
            "4  chocolate-babka     6.962768     1.0\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load data again just to be safe\n",
        "features = pd.read_csv('features.tsv', sep='\\t')\n",
        "ratings = pd.read_csv('ratings.tsv', sep='\\t')\n",
        "\n",
        "# Prepare data\n",
        "X = features.drop('recipe_slug', axis=1).values  # Feature matrix (100 x 297)\n",
        "recipe_slugs = features['recipe_slug'].values\n",
        "recipe_ratings = dict(zip(ratings['recipe_slug'], ratings['rating']))\n",
        "\n",
        "print(f\"Online LinUCB Setup:\")\n",
        "print(f\"Number of recipes: {len(recipe_slugs)}\")\n",
        "print(f\"Feature dimensions: {X.shape[1]}\")\n",
        "\n",
        "# LinUCB parameters\n",
        "ridge_alpha = 1.0\n",
        "linucb_alpha = 2.0\n",
        "d = X.shape[1]\n",
        "\n",
        "print(f\"Parameters: ridge_alpha={ridge_alpha}, linucb_alpha={linucb_alpha}\")\n",
        "\n",
        "# Initialize LinUCB state\n",
        "A = ridge_alpha * np.eye(d)  # Start with regularization matrix\n",
        "b = np.zeros(d)  # Start with zero reward accumulation\n",
        "recommendations = []  # Track recommendations made\n",
        "\n",
        "# Create recipe index mapping for quick lookup\n",
        "recipe_to_idx = {slug: i for i, slug in enumerate(recipe_slugs)}\n",
        "\n",
        "# Track which recipes have been recommended\n",
        "recommended_recipes = set()\n",
        "\n",
        "# Make 100 recommendations (one for each recipe)\n",
        "for round_num in range(100):\n",
        "    if round_num % 10 == 0:\n",
        "        print(f\"Round {round_num + 1}/100\")\n",
        "    \n",
        "    # Calculate current parameter estimate\n",
        "    A_inv = np.linalg.inv(A)\n",
        "    theta_hat = A_inv @ b\n",
        "    \n",
        "    # Calculate upper confidence bounds for all remaining recipes\n",
        "    best_recipe = None\n",
        "    best_bound = -np.inf\n",
        "    best_idx = -1\n",
        "    \n",
        "    for i, recipe in enumerate(recipe_slugs):\n",
        "        # Skip if already recommended\n",
        "        if recipe in recommended_recipes:\n",
        "            continue\n",
        "            \n",
        "        z = X[i, :]  # Feature vector for this recipe\n",
        "        \n",
        "        # Calculate upper confidence bound\n",
        "        point_estimate = z @ theta_hat\n",
        "        confidence_width = linucb_alpha * np.sqrt(z @ A_inv @ z)\n",
        "        upper_bound = point_estimate + confidence_width\n",
        "        \n",
        "        # Track best (break ties arbitrarily - first encountered wins)\n",
        "        if upper_bound > best_bound:\n",
        "            best_bound = upper_bound\n",
        "            best_recipe = recipe\n",
        "            best_idx = i\n",
        "    \n",
        "    # Ensure we found a recipe\n",
        "    if best_recipe is None:\n",
        "        print(f\"Error: No unrecommended recipes found at round {round_num + 1}\")\n",
        "        break\n",
        "    \n",
        "    # Make recommendation\n",
        "    recommended_recipe = best_recipe\n",
        "    score_bound = best_bound\n",
        "    reward = recipe_ratings[recommended_recipe]\n",
        "    \n",
        "    # Record recommendation\n",
        "    recommendations.append({\n",
        "        'recipe_slug': recommended_recipe,\n",
        "        'score_bound': score_bound,\n",
        "        'reward': reward\n",
        "    })\n",
        "    \n",
        "    # Mark as recommended\n",
        "    recommended_recipes.add(recommended_recipe)\n",
        "    \n",
        "    # Update LinUCB state with observed reward\n",
        "    z = X[best_idx, :]  # Feature vector of chosen recipe\n",
        "    A += np.outer(z, z)  # A = A + z * z^T\n",
        "    b += reward * z      # b = b + reward * z\n",
        "\n",
        "print(f\"Completed {len(recommendations)} recommendations\")\n",
        "\n",
        "# Create recommendations DataFrame\n",
        "recommendations_df = pd.DataFrame(recommendations)\n",
        "\n",
        "print(f\"\\nRecommendations summary:\")\n",
        "print(f\"Shape: {recommendations_df.shape}\")\n",
        "print(f\"Average reward: {recommendations_df['reward'].mean():.4f}\")\n",
        "print(f\"Total reward: {recommendations_df['reward'].sum():.2f}\")\n",
        "\n",
        "print(f\"\\nFirst 10 recommendations:\")\n",
        "for i in range(10):\n",
        "    rec = recommendations[i]\n",
        "    print(f\"{i+1:2d}: {rec['recipe_slug']:25} | Bound: {rec['score_bound']:.3f} | Reward: {rec['reward']:.2f}\")\n",
        "\n",
        "print(f\"\\nLast 10 recommendations:\")\n",
        "for i in range(90, 100):\n",
        "    rec = recommendations[i]\n",
        "    print(f\"{i+1:2d}: {rec['recipe_slug']:25} | Bound: {rec['score_bound']:.3f} | Reward: {rec['reward']:.2f}\")\n",
        "\n",
        "# Analyze performance over time\n",
        "cumulative_reward = np.cumsum(recommendations_df['reward'].values)\n",
        "cumulative_regret = np.arange(1, len(recommendations) + 1) - cumulative_reward  # Assume max possible reward is 1\n",
        "\n",
        "print(f\"\\nPerformance analysis:\")\n",
        "print(f\"Final cumulative reward: {cumulative_reward[-1]:.2f}\")\n",
        "print(f\"Final cumulative regret: {cumulative_regret[-1]:.2f}\")\n",
        "print(f\"Average reward per recommendation: {cumulative_reward[-1] / len(recommendations):.4f}\")\n",
        "\n",
        "# Count rewards by rating level\n",
        "reward_counts = recommendations_df['reward'].value_counts().sort_index()\n",
        "print(f\"\\nReward distribution:\")\n",
        "for reward, count in reward_counts.items():\n",
        "    print(f\"  Reward {reward}: {count} recipes\")\n",
        "\n",
        "# Save recommendations to file\n",
        "recommendations_df.to_csv('recommendations.tsv', sep='\\t', index=False)\n",
        "print(f\"\\nRecommendations saved to 'recommendations.tsv'\")\n",
        "\n",
        "# Verification\n",
        "recommendations_check = pd.read_csv('recommendations.tsv', sep='\\t')\n",
        "print(f\"Verification - loaded recommendations.tsv:\")\n",
        "print(f\"Shape: {recommendations_check.shape}\")\n",
        "print(f\"Columns: {recommendations_check.columns.tolist()}\")\n",
        "print(f\"Sample entries:\")\n",
        "print(recommendations_check.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23jv0cD0woSt"
      },
      "source": [
        "Submit \"recommendations.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi8lV2pbvWMs"
      },
      "source": [
        "## Part 7: Acknowledgments\n",
        "\n",
        "Make a file \"acknowledgments.txt\" documenting any outside sources or help on this project.\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for.\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy.\n",
        "If no acknowledgements are appropriate, just write none in the file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuNJe62UxCoH"
      },
      "source": [
        "Submit \"acknowledgments.txt\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smsTLuFcvR-I"
      },
      "source": [
        "## Part 8: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cgzHyF7wxpr"
      },
      "source": [
        "Submit \"project.ipynb\" in Gradescope."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
